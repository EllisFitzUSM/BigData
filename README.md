# Big Data & Distributed Storage
Here we list some resources that we used in our research that give more in depth information about the topics discussed in lecture.
## Distributed Computing
[Resource Management - YARN](https://www.geeksforgeeks.org/data-engineering/explain-the-role-of-yarn-yet-another-resource-negotiator-in-hadoop/)
## MapReduce
Programming model for distributed computing.

[Paper](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf)
[Apache Hadoop](https://hadoop.apache.org/)
[Video Explanation](https://www.youtube.com/watch?v=cvhKoniK5Uo&t=200s)
## (Facebook) Hive
Wrapper over Hadoop + MapReduce with SQL-like syntax.

[Paper](https://research.facebook.com/publications/hive-a-warehousing-solution-over-a-map-reduce-framework/)
[Apache Hive](https://hive.apache.org/)
## (Facebook) Presto
"SQL On Everything" - Use SQL to source data from multiple different data stores.

[Paper](https://research.facebook.com/publications/presto-sql-on-everything/)
[PrestoDB](https://prestodb.io/)
[ELI5 Explanation](https://youtu.be/BGqIkiUtKHY?si=hEQtfqp4Gyy9iU4f)
## (AirDNA) Data Lake 
[AirDNA: How The Data Works](https://www.airdna.co/airdna-data-how-it-works) 
## (Linkedin) Kafka
[How Linkedin Customizes its 7 Trillion Message Kafka Ecosystem](https://blog.bytebytego.com/p/how-linkedin-customizes-its-7-trillion)
## Hadoop Distributed File System
[Hadoop - HDFS (Hadoop Distributed File System)](https://www.geeksforgeeks.org/data-engineering/hadoop-hdfs-hadoop-distributed-file-system/)
## (Apache) Spark
Language engine for data science and machine learning on single machine or multiple node clusters. Offers Python API/wrapper [PySpark](https://spark.apache.org/docs/latest/api/python/index.html).

[Website](https://spark.apache.org/)
